{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate with Web DeepL\n",
    "\n",
    "We also tried to translate the original instruction dataset which is consisted of english data with Web DeepL Translator.\n",
    "We utilitzed Colab to run these code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Chrome Driver\n",
    "\n",
    "Using Selenium in Colab, it will occur PermissionError. Therefore, we need to download Chromedriver before to run the code about Selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium\n",
    "!pip install datasets\n",
    "!apt-get update\n",
    "!apt install chromium-chromedriver\n",
    "!cp /usr/lib/chromium-browser/chromedriver/usr/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions\n",
    "\n",
    "Several funstions were defined before starting translation.\n",
    "These funstions are almost same compared to the functions of `deepl_translate_api.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "\n",
    "def dataset_load(data_type, data_path):\n",
    "    dataset = []\n",
    "    if data_type == \"hf\":\n",
    "        loaded_dataset = load_dataset(data_path, split=\"train\")\n",
    "        i = 0\n",
    "        for line in loaded_dataset:\n",
    "            if i == 0:\n",
    "                columns = list(line.keys())\n",
    "                i += 1\n",
    "            dataset.append(line)\n",
    "    elif data_type == \"json\":\n",
    "        with open(data_path, \"r\") as f:\n",
    "            dataset = json.load(f)\n",
    "        columns = list(dataset[0].keys())\n",
    "    else:\n",
    "        raise ValueError(\"The '--data_type' should be 'hf' or 'json'!!\")\n",
    "    \n",
    "    return dataset, columns\n",
    "\n",
    "def type_cls(input_data):\n",
    "    if \"```\" in input_data:\n",
    "        return \"code\"\n",
    "    elif len(input_data.split(\"$\")) % 2 == 1 and len(input_data.split(\"$\")) >= 5:\n",
    "        return \"math\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "type_list = {\"math\": [\"$\", \"ABC\"], \"code\": [\"```\", \"BLOCKED_CODE\"]}\n",
    "\n",
    "def data_process(input_data, data_type):\n",
    "    splited = input_data.split(type_list[data_type][0])\n",
    "    blocked_list = []\n",
    "\n",
    "    for i in range(len(splited)):\n",
    "        if i % 2 == 1:\n",
    "            blocked_list.append(type_list[data_type][0] + splited[i] + type_list[data_type][0])\n",
    "            splited[i] = type_list[data_type][1]\n",
    "\n",
    "    input_text = \" \".join(splited)\n",
    "\n",
    "    output = deepl_web(input_text)\n",
    "\n",
    "    output = output.split()\n",
    "\n",
    "    for i in range(len(output)):\n",
    "        if output[i] == type_list[data_type][1]:\n",
    "            output[i] = blocked_list[0]\n",
    "            blocked_list.pop(0)\n",
    "\n",
    "    output = \" \".join(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "deepl_info = {\"input_css\": \"div.relative.flex-1 d-textarea\", \"translation_xpath\": '//*[@id=\"headlessui-tabs-panel-7\"]/div/div[1]/section/div/div[2]/div[3]/section/div[1]/d-textarea/div/p', \"button_css\": \"#translator-source-clear-button\"}\n",
    "\n",
    "def deepl_web(input_text):\n",
    "    # Get thie inupt_area\n",
    "    input_area = driver.find_element(By.CSS_SELECTOR, deepl_info[\"input_css\"])\n",
    "\n",
    "    # Send the text\n",
    "    input_area.send_keys(input_text)\n",
    "\n",
    "    # Wait for translation to appear on the web page    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        translation_text = driver.find_element(By.XPATH, deepl_info[\"translation_xpath\"])\n",
    "        content = translation_text.text\n",
    "    except Exception as e:\n",
    "        button = driver.find_element(By.CSS_SELECTOR, deepl_info[\"button_css\"])\n",
    "        button.click()\n",
    "        print(\"Retrying due to an error.\")\n",
    "        print(e)\n",
    "        return deepl_web()\n",
    "    \n",
    "    # clear(X) button\n",
    "    button = driver.find_element(By.CSS_SELECTOR, deepl_info[\"button_css\"])\n",
    "    button.click()\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run translation\n",
    "\n",
    "All done!\n",
    "You can run translation with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Selenium driver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "deepl_url = 'https://www.deepl.com/ko/translator'\n",
    "driver.get(deepl_url)\n",
    "\n",
    "dataset, columns = dataset_load(\"hf\", \"StudentLLM/Open-Wyvern-74k\")\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    translated_text = {}\n",
    "    for column in columns:\n",
    "        if column == \"category\":\n",
    "            translated_text[column] = dataset[i][column]\n",
    "            continue\n",
    "\n",
    "        input_data = dataset[i][column]\n",
    "\n",
    "        if input_data:\n",
    "            data_type = type_cls(input_data=input_data)\n",
    "        else:\n",
    "            translated_text[column] = dataset[i][column]\n",
    "            continue\n",
    "\n",
    "        if data_type:\n",
    "            translated_text[column] = data_process(input_data=input_data, data_type=data_type)\n",
    "        else:\n",
    "            translated_text[column] = deepl_web(input_text=input_data)\n",
    "\n",
    "    with open(\"data_pipleine/ko-open-wyvern.json\", \"r\") as f:\n",
    "        ko_wyvern_dataset = json.load(f)\n",
    "\n",
    "    f.close()\n",
    "        \n",
    "    ko_wyvern_dataset.append(translated_text)\n",
    "\n",
    "    with open(\"data_pipleine/ko-open-wyvern.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(ko_wyvern_dataset, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    json_file.close()\n",
    "\n",
    "print(\"Translation is all done!!\")\n",
    "\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
